{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/volgasezen/is584/blob/main/Lab 4/Part 2 - Word Embeddings CBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVZyWSZZhjg3"
      },
      "source": [
        "# Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvEp96LYhnFy"
      },
      "source": [
        "In this tutorial, we will learn to create word embeddings  from scratch.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG0elsW1jcDa"
      },
      "source": [
        "## Embeddings and Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWEU9A2MjhLM"
      },
      "source": [
        "Embeddings are created and trained with one hot encoding vector and linear layers. For example; "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoUOXN5ixhSD",
        "outputId": "0d14ad2a-3df8-4c96-dcce-143dfb354630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jDTfraEkXOh",
        "outputId": "7ba08cfc-1573-474c-e20a-08d6ac1a1c28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input:  tensor([0, 1, 2])\n",
            "one hot :\n",
            "  tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n",
            "linear layer: \n",
            " Parameter containing:\n",
            "tensor([[0.1858, 0.1128, 0.2447],\n",
            "        [0.1200, 0.0576, 0.4244]], requires_grad=True)\n",
            "output:\n",
            "  tensor([[0.1858, 0.1200],\n",
            "        [0.1128, 0.0576],\n",
            "        [0.2447, 0.4244]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "input = torch.arange(0, 3)\n",
        "one_hot =nn.functional.one_hot(input,num_classes = 3).type(torch.FloatTensor)\n",
        "linear_layer=nn.Linear(in_features=3,out_features=2,bias=False)\n",
        "output_layer =linear_layer(one_hot)\n",
        "print('input: ', input)\n",
        "print('one hot :\\n ', one_hot)\n",
        "print('linear layer: \\n', linear_layer.weight)\n",
        "print('output:\\n ', output_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r54g6HnqbbN"
      },
      "source": [
        "The above example shows that our outputs are similar to the weights of the linear layer. The first column refers to the embedding of `word 0`, the second column refers to the embedding of the `word 1` so on.  We can train these weights to obtain the final word embeddings.\n",
        "\n",
        "For example, in a data set containing one million different word tokens and an embedding size of 300, we will obtain a layer with 300 million parameters. PyTorch provides the `nn.Embedding` module to speed up the process, which we mentioned in our previous tutorials. [Pytorch documentation]( https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) page about this module states that “A simple lookup table that stores embeddings of a fixed dictionary and size.”. Let’s look at the following example;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w70Gc9lotJ7v",
        "outputId": "20ba417f-d398-400f-cd3f-4649d4936125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input:  tensor([0, 1, 2])\n",
            "embedding layer: \n",
            " Parameter containing:\n",
            "tensor([[ 0.5853, -0.1032],\n",
            "        [ 2.1192,  0.0506],\n",
            "        [-0.2265,  1.2768]], requires_grad=True)\n",
            "output:\n",
            "  tensor([[ 0.5853, -0.1032],\n",
            "        [ 2.1192,  0.0506],\n",
            "        [-0.2265,  1.2768]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ],
      "source": [
        "input = torch.arange(0, 3)\n",
        "embedding_layer = nn.Embedding(num_embeddings=3,embedding_dim=2)\n",
        "output = embedding_layer(input)\n",
        "print('input: ', input)\n",
        "print('embedding layer: \\n', embedding_layer.weight)\n",
        "print('output:\\n ', output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjv5zcOUt3NI"
      },
      "source": [
        "The embedding layer provides improved optimization and additional parameters like padding.  For more information about `nn.Embedding’, I suggest you check [Pytorch documentation](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) page."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX6_OiU1i3bt"
      },
      "source": [
        "## CBOW\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIFbaZvZvRNP"
      },
      "source": [
        "We will implement the Continuous Bag of Words (CBOW) in this tutorial. We will follow one of the tutorials provided by the PyTorch tutorial page. Let's start with importing the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z7zfdYYvwoE",
        "outputId": "16fafeb8-a9e1-4d87-d2ad-00136ef6c5ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRVIPr7O2uhi"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L7neVav9ok3N"
      },
      "outputs": [],
      "source": [
        "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
        "Computational processes are abstract beings that inhabit computers.\n",
        "As they evolve, processes manipulate other abstract things called data.\n",
        "The evolution of a process is directed by a pattern of rules\n",
        "called a program. People create programs to direct processes. In effect,\n",
        "we conjure the spirits of the computer with our spells.\"\"\".split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G4WsJNkooM5"
      },
      "source": [
        "We will use the corpus shown above.  Please note that we are skipping the tokenizing step for this example for simplicity.    \n",
        "As you know, CBOW uses context words (words surrounding the target word) to predict the center (or target) word.    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evgAEDKUs_i1"
      },
      "source": [
        "![CBOW.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8KMsuMAtDZa"
      },
      "source": [
        "As a first step, let’s create our context and target sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JBW2H04tf01",
        "outputId": "215a622e-e9d3-48a7-8b68-c2639e0ff0a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea'), (['the', 'idea', 'a', 'computational'], 'of'), (['idea', 'of', 'computational', 'process.'], 'a'), (['of', 'a', 'process.', 'Computational'], 'computational'), (['a', 'computational', 'Computational', 'processes'], 'process.'), (['computational', 'process.', 'processes', 'are'], 'Computational')]\n"
          ]
        }
      ],
      "source": [
        "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
        "\n",
        "data = []\n",
        "for i in range(CONTEXT_SIZE, len(raw_text) - CONTEXT_SIZE):\n",
        "    context = raw_text[(i - CONTEXT_SIZE):(i)]+ raw_text[(i+1): (i+1 + CONTEXT_SIZE)]      \n",
        "    target = raw_text[i]\n",
        "    data.append((context, target))\n",
        "\n",
        "print(data[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_CaBdijwUmv",
        "outputId": "03940c15-70c3-43b0-af61-673457e54ecd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "49\n"
          ]
        }
      ],
      "source": [
        "vocab = set(raw_text)\n",
        "vocab_size = len(vocab)\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p6nengSwbQW"
      },
      "source": [
        "Now that we created our dataset, our next step is to convert words into numbers.  \n",
        "Luckily due to our small corpus, we only have 49 different words. Working on bigger datasets like Wikipedia or Twitter means working on vocabularies including thousands of words.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as_NvJ18yvVw",
        "outputId": "04027b66-38e0-4e97-a5a4-f3424c0a9445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "word to ix converts word to numbers: word_to_ix[\"We\"] -> 31\n",
            "ix to word converts word to numbers: ix_to_word[28] -> program.\n"
          ]
        }
      ],
      "source": [
        "word_to_ix = {word: i for i, word in enumerate(vocab)}  # a dictionary that converts words to ids\n",
        "ix_to_word = {ix:word for ix, word in enumerate(vocab)} # a dictionary that converts ids to words\n",
        "\n",
        "print('word to ix converts word to numbers: word_to_ix[\"We\"] ->', word_to_ix[\"We\"])\n",
        "print(\"ix to word converts word to numbers: ix_to_word[31] ->\", ix_to_word[31])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sce09h4hzU1M",
        "outputId": "67113b44-9881-4ee1-ad2b-0b538ac01897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Make context vector function convert our data set to tensors:\n",
            " ['We', 'are', 'to', 'study'] -> tensor([31, 44, 32, 10])\n",
            "\n",
            "For target we can still use: \n",
            "word_to_ix[data[0][1]]-> 33\n"
          ]
        }
      ],
      "source": [
        "def make_context_vector(context, word_to_ix):  # function to convert our word array to  torch tensor\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "print(\"Make context vector function convert our data set to tensors:\\n\", data[0][0],\"->\", make_context_vector(data[0][0], word_to_ix))\n",
        "print(\"\\nFor target we can still use: \\nword_to_ix[data[0][1]]->\",word_to_ix[data[0][1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHJQ4dOT2Lqh"
      },
      "source": [
        "### Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVRPIvzmD8w9"
      },
      "source": [
        "Next, we will implement our network while utilizing the nn.Embedding module in our network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GeAZgWBZ1r9-"
      },
      "outputs": [],
      "source": [
        "class CBOWnetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim,hidden_dim):  \n",
        "        super(CBOWnetwork, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)  \n",
        "        self.linear1 = nn.Linear(embedding_dim, hidden_dim)   \n",
        "        self.relu1 = nn.ReLU()        \n",
        "        self.linear2 = nn.Linear(hidden_dim, vocab_size)  # We need output size equal to vocab_size\n",
        "        self.softmax = nn.LogSoftmax(dim = -1)\n",
        "        \n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = sum(self.embeddings(inputs)).view(1,-1)   # as CBOW model says we will sum our embeddings .view(1,-1) prepares  our output for next layer.\n",
        "        x = self.linear1(embeds)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        x = self.linear2(x)\n",
        "        x = self.softmax(x)   \n",
        "        return x\n",
        "        \n",
        "    def get_word_embedding(self, word):\n",
        "        word = torch.tensor([word_to_ix[word]])\n",
        "        return self.embeddings(word).view(1,-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82gQWq_Y6_wo"
      },
      "source": [
        "The CBOW Network above contains two linear layers with RELU activation between layers, and a LogSoftMax layer at the end. This SoftMax function returns probability distribution over our vocabulary. \n",
        "\n",
        "Let’s initiate our network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vzHZPIbl3BFh"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 5  # For this example, let's choose 5 as our embedding dimension. You are welcome to try different dimension sizes.\n",
        "loss_function = nn.NLLLoss()  # The negative log-likelihood loss is useful when we have N classes.\n",
        "HIDDEN_DIM = 10\n",
        "\n",
        "model = CBOWnetwork(len(vocab), EMBEDDING_DIM,HIDDEN_DIM)   #If you want to work on the GPU, you can add the `.cuda()` to end. Because it is a small network, we will work on the CPU.\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khDR_dn5-6Q7"
      },
      "source": [
        "Our last step is to train our network/embeddings. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPfnB3ga4KbK",
        "outputId": "545f5662-0488-4173-e1c4-2d00c8dd5569"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 50 avarage epoch loss: 3.547443918113051\n",
            "epoch 100 avarage epoch loss: 3.172199052983317\n",
            "epoch 150 avarage epoch loss: 2.8295482386802804\n",
            "epoch 200 avarage epoch loss: 2.4886438918524774\n",
            "epoch 250 avarage epoch loss: 2.1404235085536696\n",
            "epoch 300 avarage epoch loss: 1.8023953607370113\n",
            "epoch 350 avarage epoch loss: 1.492953394250623\n",
            "epoch 400 avarage epoch loss: 1.2293770349231259\n",
            "epoch 450 avarage epoch loss: 1.010343200559246\n",
            "epoch 500 avarage epoch loss: 0.8288299792670998\n",
            "epoch 550 avarage epoch loss: 0.6781097398749714\n",
            "epoch 600 avarage epoch loss: 0.5550598050628243\n",
            "epoch 650 avarage epoch loss: 0.4554936982819746\n",
            "epoch 700 avarage epoch loss: 0.37557054323882894\n",
            "epoch 750 avarage epoch loss: 0.3118193883705756\n",
            "epoch 800 avarage epoch loss: 0.2608311102436534\n"
          ]
        }
      ],
      "source": [
        "losses = []   # for keeping the losses\n",
        "EPOCHS = 800  # because of our tiny dataset we need to increase our epoch count\n",
        "j =0\n",
        "for epoch in range(EPOCHS):    \n",
        "    total_loss = 0\n",
        "    i=0 \n",
        "    j +=1\n",
        "    for context, target in data:     #lets get our context and target\n",
        "        \n",
        "        # Remove the gradients for next iteration\n",
        "        model.zero_grad()   \n",
        "       \n",
        "        # Convert the corpus in to integers.\n",
        "        context_idxs = make_context_vector(context,word_to_ix)  \n",
        "        #print(\"Context id: \",context_idxs)\n",
        "      \n",
        "        # forward pass\n",
        "        log_probs = model(context_idxs)\n",
        "\n",
        "        # calculate the Loss\n",
        "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
        "        #print(loss)\n",
        "\n",
        "        # backward Pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient decent using optimizer \n",
        "        optimizer.step()\n",
        "        i += 1\n",
        "        # \n",
        "        total_loss += loss.item()\n",
        "    if j%50 ==0:\n",
        "      print(\"epoch\", j ,\"avarage epoch loss:\", total_loss/i)\n",
        "    losses.append(total_loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1PyLO3UEBcv"
      },
      "source": [
        "### Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNLi9l-UDioP"
      },
      "source": [
        "Now that we trained our network. Let's see a prediction example;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8-bQaka-WqJ",
        "outputId": "c7232bcf-71ee-47df-d7eb-beee8a2ae385"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: are\n"
          ]
        }
      ],
      "source": [
        "context = ['Computational','processes', 'abstract','beings']\n",
        "context_vector = make_context_vector(context, word_to_ix)\n",
        "result = model(context_vector)\n",
        "\n",
        "print(f'Prediction: {ix_to_word[torch.argmax(result[0]).item()]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKeEuz1MD0Pa",
        "outputId": "7437fe5e-47cb-41d2-fc03-662747dd47d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: about\n"
          ]
        }
      ],
      "source": [
        "context = ['We','study', 'abstract','things']  #let's try phrase that does not exist in our data\n",
        "context_vector = make_context_vector(context, word_to_ix)\n",
        "result = model(context_vector)\n",
        "\n",
        "print(f'Prediction: {ix_to_word[torch.argmax(result[0]).item()]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkIxeOeFFHEC"
      },
      "source": [
        "The `get_word_embeddings` function of our network returns trained embeddings of the given word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kChb3jayJV_n",
        "outputId": "10c073fa-87fc-4191-ed32-4ed2507bb0d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.9280, -0.3002,  0.1396,  0.1612,  1.7412]],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_word_embedding('are')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWQdEm0l0FFz"
      },
      "source": [
        "## Another CBOW example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1XSM8ZJ0L2E"
      },
      "source": [
        "We will now change our input to observe the quality of the embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hghX45PJ0JaU"
      },
      "outputs": [],
      "source": [
        "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
        "              We are about to learn the idea of a computational process.\n",
        "              We are about to study the way of a computational process.\n",
        "              We are about to learn the way of a computational process.\"\"\".split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyJwxZsX2Bd8"
      },
      "source": [
        "As you can see, the new text has 4 sentences that replace `study` with `learn` and `idea` with `way`. If we look at the CBOW model, embeddings of these words will be similar after training. Let’s create our network and observe the embeddings of these words while training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "s6oi-aAe0a-w"
      },
      "outputs": [],
      "source": [
        "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
        "data = []\n",
        "for i in range(CONTEXT_SIZE, len(raw_text) - CONTEXT_SIZE):\n",
        "    context = raw_text[(i - CONTEXT_SIZE):(i)]+ raw_text[(i+1): (i+1 + CONTEXT_SIZE)]      \n",
        "    target = raw_text[i]\n",
        "    data.append((context, target))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1UPu-ICj1aZ0"
      },
      "outputs": [],
      "source": [
        "vocab = set(raw_text)\n",
        "vocab_size = len(vocab)\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "ix_to_word = {ix:word for ix, word in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8kMveHGC1q22"
      },
      "outputs": [],
      "source": [
        "class CBOWnetwork(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):  \n",
        "        super(CBOWnetwork, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(embedding_dim, vocab_size)   \n",
        "        self.softmax = nn.LogSoftmax(dim = -1)\n",
        "    def forward(self, inputs):\n",
        "        embeds = torch.sum(self.embeddings(inputs),0).view(1,-1)\n",
        "        x = self.linear1(embeds)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "    def get_word_embedding(self, word):\n",
        "        word = torch.tensor([word_to_ix[word]])\n",
        "        return self.embeddings(word).view(1,-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8XBIojZV1xck"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 1  \n",
        "loss_function = nn.NLLLoss()  # The negative log likelihood loss is useful when we have N number of clases\n",
        "model = CBOWnetwork(len(vocab), EMBEDDING_DIM)   #If you want to work on the GPU you can add the `.cuda()` to end. Because it is a small network, we will work on CPU.\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_pfPmQm11cW",
        "outputId": "10622520-c541-4d7d-deca-a0c1dea3ec15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch  0  avarage loss  3.5519193395972253\n",
            "study: -0.6405587792396545 learn: 1.2428487539291382\n",
            "idea: 0.05227378383278847 way: -0.21945291757583618 \n",
            "\n",
            "epoch  100  avarage loss  2.5064186573028566\n",
            "study: -0.536053478717804 learn: 1.178978443145752\n",
            "idea: -0.0585571825504303 way: -0.3066433072090149 \n",
            "\n",
            "epoch  200  avarage loss  2.2902836710214616\n",
            "study: -0.43080416321754456 learn: 1.1217738389968872\n",
            "idea: -0.16198143362998962 way: -0.38646429777145386 \n",
            "\n",
            "epoch  300  avarage loss  2.0971345767378806\n",
            "study: -0.2790960669517517 learn: 1.0647934675216675\n",
            "idea: -0.21926042437553406 way: -0.41386085748672485 \n",
            "\n",
            "epoch  400  avarage loss  1.940844613313675\n",
            "study: -0.09532274305820465 learn: 1.0030118227005005\n",
            "idea: -0.2566532790660858 way: -0.4173741042613983 \n",
            "\n",
            "epoch  500  avarage loss  1.826148296892643\n",
            "study: 0.09223043918609619 learn: 0.9500172138214111\n",
            "idea: -0.286149263381958 way: -0.41590288281440735 \n",
            "\n",
            "epoch  600  avarage loss  1.7426644623279572\n",
            "study: 0.2573149502277374 learn: 0.9071144461631775\n",
            "idea: -0.31887415051460266 way: -0.42354047298431396 \n",
            "\n",
            "epoch  700  avarage loss  1.6761404246091842\n",
            "study: 0.39295345544815063 learn: 0.8753654956817627\n",
            "idea: -0.3558494746685028 way: -0.44096601009368896 \n",
            "\n",
            "epoch  800  avarage loss  1.6212268710136413\n",
            "study: 0.5017491579055786 learn: 0.8552848100662231\n",
            "idea: -0.3943362236022949 way: -0.46427488327026367 \n",
            "\n",
            "epoch  900  avarage loss  1.575690397620201\n",
            "study: 0.5878031849861145 learn: 0.845004677772522\n",
            "idea: -0.4330129027366638 way: -0.4910382330417633 \n",
            "\n",
            "epoch  1000  avarage loss  1.5372776880860328\n",
            "study: 0.6554860472679138 learn: 0.8418023586273193\n",
            "idea: -0.47145524621009827 way: -0.5199540257453918 \n",
            "\n",
            "epoch  1100  avarage loss  1.5038068518042564\n",
            "study: 0.70903080701828 learn: 0.8434532880783081\n",
            "idea: -0.5093418955802917 way: -0.5500666499137878 \n",
            "\n",
            "epoch  1200  avarage loss  1.473745345324278\n",
            "study: 0.7520486116409302 learn: 0.8485217094421387\n",
            "idea: -0.5463005304336548 way: -0.5805800557136536 \n",
            "\n",
            "epoch  1300  avarage loss  1.446190993487835\n",
            "study: 0.7873249650001526 learn: 0.8560888767242432\n",
            "idea: -0.5819951295852661 way: -0.6108783483505249 \n",
            "\n",
            "epoch  1400  avarage loss  1.4206330522894859\n",
            "study: 0.8168901801109314 learn: 0.8655023574829102\n",
            "idea: -0.6161686182022095 way: -0.6405118107795715 \n",
            "\n",
            "epoch  1500  avarage loss  1.3967681623995305\n",
            "study: 0.8422070741653442 learn: 0.8762514591217041\n",
            "idea: -0.6486387252807617 way: -0.6691550612449646 \n",
            "\n",
            "epoch  1600  avarage loss  1.3744047187268733\n",
            "study: 0.8643276691436768 learn: 0.8879210948944092\n",
            "idea: -0.6792978644371033 way: -0.6965893507003784 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "losses = []   # for keeping the losses\n",
        "EPOCHS = 1601  # lower learning rate and small data\n",
        "\n",
        "j=0\n",
        "for epoch in range(EPOCHS):    \n",
        "    total_loss = 0\n",
        "    i=0 \n",
        "    for context, target in data:     #lets get our context and target\n",
        "        \n",
        "        # Remove the gradients for next iteration\n",
        "        model.zero_grad()   \n",
        "       \n",
        "        # Convert the corpus in to integers.\n",
        "        context_idxs = make_context_vector(context,word_to_ix)  \n",
        "        #print(\"Context id: \",context_idxs)\n",
        "      \n",
        "        # forward pass\n",
        "        log_probs = model(context_idxs)\n",
        "\n",
        "        # calculate the Loss\n",
        "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
        "        #print(loss)\n",
        "\n",
        "        # backward Pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient decent using optimizer \n",
        "        optimizer.step()\n",
        "\n",
        "        # \n",
        "        total_loss += loss.item()\n",
        "        i +=1\n",
        "    if j%100 ==0:\n",
        "      print(f'epoch  {j}  avarage loss  {(total_loss/i):0}')\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        print(\"study:\", model.get_word_embedding('study').item(),\"learn:\", model.get_word_embedding('learn').item())\n",
        "        print(\"idea:\", model.get_word_embedding('idea').item(),\"way:\", model.get_word_embedding('way').item(), '\\n')\n",
        "      model.train()\n",
        "    losses.append(total_loss)\n",
        "    j += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bKflUIi3fr2"
      },
      "source": [
        "After random initialization of the embedding layer, weights of these words start to converge with each epoch of training."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "Word Embeddings.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
