{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hvcwopK7EU5"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/volgasezen/di504/blob/main/Lab1/Intro_to_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC-p2CGy6McK"
      },
      "source": [
        "<h1 style=\"margin-bottom:0\">IS 584: Deep Learning for Text Analytics</h1>\n",
        "<br>\n",
        "<h3 style=\"margin-top:0\">Lab 3 / Part 2: News Article Classification with PyTorch</h2>\n",
        "<h4 style=\"margin-top:0\">Given by Volga Sezen</h4>\n",
        "<i>Thanks to Ayberk Aydın and Arif Ozan Kızıldağ for the feedback.</i>\n",
        "<br>\n",
        "\n",
        "-----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSyKS8FfuX5y"
      },
      "source": [
        "## Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wv06sTyrLnwK"
      },
      "outputs": [],
      "source": [
        "!pip install torch==2.3.1 --index-url https://download.pytorch.org/whl/cu121 --no-dependencies -q\n",
        "!pip install torchtext -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJaCgY0b6CDo",
        "outputId": "31cc9779-594d-4903-ab72-35ff4413c2b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch version: 2.3.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(f'torch version: {torch.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ydeZvm3A-37"
      },
      "source": [
        "## torchtext (depracated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKQtPE_SBNSb"
      },
      "source": [
        "Aside from scientific computing, PyTorch has many utilities for handling data for machine learning and deep learning tasks. You can sample, shuffle, split and batch data as well as apply transformations on them.\n",
        "\n",
        "Since the development of ``torchtext`` stopped, the most recent version of pytorch it can run with is 2.3.1, hence when running on colab the following commands has to be executed.\n",
        "\n",
        "To be able to access the AG_NEWS dataset we will use the `datasets` library of HuggingFace. It has its own dataset structure, but we will be converting it into a machine-readable form with data utilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz9oFsf98XkV",
        "outputId": "3da559cb-dbc2-4f38-815e-9a2b4b3addfe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets -q\n",
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"fancyzhx/ag_news\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-4awMGU-XPm",
        "outputId": "43e952f1-7647-4fb8-fa2c-467d39a3c287"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\",\n",
              " 'label': 2}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEmej_fM_EgE",
        "outputId": "f8f89ac6-ca87-4151-863f-00a01dff9350"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torchtext\n",
        "torchtext.disable_torchtext_deprecation_warning()\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "tokenizer = get_tokenizer('spacy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBzINfH4_fXe"
      },
      "outputs": [],
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(ds['train']['text']), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaFHdRN6_uEY",
        "outputId": "edd6551f-979b-4142-cfb7-ccdc86f55dcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 110933\n"
          ]
        }
      ],
      "source": [
        "print(\"Unique tokens in TEXT vocabulary:\",len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fO_4y52JAFCJ",
        "outputId": "2794da4a-11f0-44dc-bb93-c1a3246a3762"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input to the text_transform: A sentence in English probably won't contain the word 'hendese'.\n",
            "Output of the text_transform: [46, 3668, 8, 1879, 1758, 2500, 250, 6808, 1, 2518, 75, 0, 75, 3]\n"
          ]
        }
      ],
      "source": [
        "text_transform = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "\n",
        "# Print out the output of text_transform\n",
        "\n",
        "test_input = \"A sentence in English probably won't contain the word 'hendese'.\"\n",
        "\n",
        "print(f\"Input to the text_transform: {test_input}\")\n",
        "print(f\"Output of the text_transform: {text_transform(test_input)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "pS-oz3qI-jm4",
        "outputId": "2e449505-5629-4083-d37a-fc4dab112c6d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import itertools\n",
        "from collections import Counter, OrderedDict\n",
        "\n",
        "words = list(itertools.chain.from_iterable(yield_tokens(ds['train']['text'])))\n",
        "\n",
        "counter = Counter(words)\n",
        "sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "frequencies = [x[1] for x in sorted_by_freq_tuples]\n",
        "\n",
        "plt.plot(frequencies)\n",
        "plt.title('Sorted logarithmic frequencies of each word')\n",
        "# plt.xscale('log')\n",
        "plt.yscale('log')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function does the following:\n",
        "\n",
        "* Iterates over each row in the batch. (Batch size is defined later.)\n",
        "* Tokenizes the \"text\" column\n",
        "* Calculates the length of the text\n",
        "* Turns the text, label and \"checkpoints\" to tensors\n",
        "\n",
        "Since we use \"extend\" method of lists, we will have one giant list. To distinguish one sentence from another we need \"checkpoints\" based on the length of each sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9fuJeqhAiW9"
      },
      "outputs": [],
      "source": [
        "def collate(batch):\n",
        "    texts, labels, offsets = [], [], [0]\n",
        "\n",
        "    for item in batch:\n",
        "        text, label = item.values()\n",
        "        texts.extend(text_transform(text))\n",
        "        offsets.append(len(text_transform(text)))\n",
        "        labels.append(label)\n",
        "\n",
        "    texts = torch.tensor(texts)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=-1)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    return texts, labels, offsets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use this collate function inside the DataLoader class. Here we can define the dataset, batch size, and control shuffling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gfiwnQSDInL",
        "outputId": "c4eb99cc-387f-44eb-f81e-c69afab41f11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([   445,    572,   2057,  50436,   1196,   1718,      1,   1380,     14,\n",
              "             30,     15,     30,      5,   4033,      5,  10267,      2,    445,\n",
              "            420,     22,  95259,      7,   8377,      5,  39309,      2,     45,\n",
              "           4736,   3034,    372,      3,  17829,   5251,   6386,   7993,  10805,\n",
              "             14,     30,     15,     30,      5,   5024,    929,    354,  17829,\n",
              "          74890,     28,      6,   5044,     11,    514,    528,      5,  17101,\n",
              "              9, 101573,   2669,      8,      1,    799,    260,      2,     28,\n",
              "           4398, 102776,   8666,     10,    220,    353,      7,      1,    139,\n",
              "              3,    165,      9,   2763,  12828,    347,     75,   1953,     14,\n",
              "             30,     15,     30,      5,  10357,    714,    107,   4561,  32382,\n",
              "              1,    393,      9,      1,   1186,     11,    326,     45,    187,\n",
              "          62037,     43,      1,    388,    139,    116,     87,    207,      1,\n",
              "           7429,      7,  47842,  18184,      3,     73,  13729,    165,   9294,\n",
              "             31,  12873,   1589,   8212,     14,     30,     15,     30,      5,\n",
              "           7289,     41,   6113,     96,  95922,     31,      1,    924,   3947,\n",
              "              8,    802,     73,  90933,    661,      6,    925,   3164,     97,\n",
              "         107519,      2,     34,     96,    307,     26,     10,    117,      3,\n",
              "            165,    107,   7051,      4,    129,      5,     93,    148,      2,\n",
              "           8585,     42,  15528,      4,     38,    393,     14,     99,     15,\n",
              "             99,      5,  86452,     90,     96,    107,      2,  12501,   2106,\n",
              "              9,  18357,  10992,      2,   4106,      6,     42,    422,  15528,\n",
              "           3999,     89,    275,    171,      1,     38,    419,    592,      3,\n",
              "            347,   1304,    322,      2,    375,   1961,   1123,   7229,     14,\n",
              "             30,     15,     30,      5,    347,    751,   1482,    329,     10,\n",
              "          74052,   4856,    411,   3055,     11,      1,     47,     20,     96,\n",
              "            107,   2400,    389,     12,     13,  64532,    741,      2,  15541,\n",
              "              6,   1848,   1186,     31,    292, 100234,     69,     14,  15246,\n",
              "             15,   2659,   4297,  12843,      8,   3786,   1903,     14,     33,\n",
              "             15,     33,      5,  10130,      7,      1,    391,     22,   1087,\n",
              "            770,    139,   2454,   1614,    431,     27,     12,     13,  48497,\n",
              "            141,      8,      1,    325,     87,      4,     12,     13,  64623,\n",
              "           7282,      2,      1,   4170,   1258,   3484,     26,     60,      3,\n",
              "           1381,   1277,    597,  17525,     43,   1658,     14,   2251,     15,\n",
              "           2251,      5,   3240,    162,   7094,    119,      6,   1859,      8,\n",
              "           1215,      2,      9,     42,    693,     11,   4333,   1919,    431,\n",
              "             77,     87,      2,      1,    103,     26,     60,      2,   8057,\n",
              "              1,    393,     24,   2945,     31,      6,  31847,   4855,      3,\n",
              "           3939,   1408,     14,   3558,     15,   3558,      5,    247,  11527,\n",
              "              6,  81279,      8,  85282,      2,   5246,  68884,  10876,   1280,\n",
              "              4,    418,     20,      1,    835,    577,     21,      6,   1445,\n",
              "           1377,   3888,    354,     21,     34,   1015,   1821,   5716,      7,\n",
              "             12,     13,  64594,      3,   5462,     39,      2,      6,    570,\n",
              "          22817,   3112,     27,     35,   9779,      4,    852,    111,  92772,\n",
              "             79,    984,   1919,   1049,    238,     35,  10224,      3,    375,\n",
              "              2,     21,   3088,      2,     70,   1516,    984,     37,      1,\n",
              "          46269,   2108,     31,   1655,   3437,      2,     70,    113,  10876,\n",
              "              3,    445,    572,   2057,  50436,   1196,   1718,      1,   1380,\n",
              "             12,    118,    124,     14,     30,     15,      5,   4033,      5,\n",
              "          10267,      2,    445,    420,     22,  14637,     12,   3501,      7,\n",
              "           8377,      5,  39309,      2,     45,   4736,   3034,    372,      3,\n",
              "            165,      9,   2763,  12828,    347,     75,   1953,     12,    118,\n",
              "            124,     14,     30,     15,      5,  10357,    714,    107,   4561,\n",
              "           1740,     12,     79,      1,    393,      9,      1,   1186,     11,\n",
              "            326,     45,    187,      4,     12,   8568,     43,      1,    388,\n",
              "            139,    116,     87,    207,      1,   7429,      7,      1,     12,\n",
              "           1433,  18184,      3,    142,   6334,     11,   1561,      4,  16782,\n",
              "            475,      5,    315,  12562,     12,   4609,     14,     30,     15,\n",
              "              5,   1561,    140,    369,   2195,      4,  45965,  22892,     12,\n",
              "             96,    107,    114,    836,     45,    797, 102307,     27,   8381,\n",
              "             86,     12,   5029,    464,    128,     14,  14595,     15,      7,\n",
              "            714,      2,    315,     22,   1561,   3757,     26,     12,    117,\n",
              "              2,   1107,     17,    107,     97,    627,   1489,      3,  11658,\n",
              "              5,   1561,    656,   5812,    322,   6683,      5,  14524,     12,\n",
              "           4193,     14,     30,     15,      5,  11658,      5,   1561,     96,\n",
              "           4643,    397,   1950,     12,   2683,   1855,      4,   3063,    148,\n",
              "            714,    107,      2,   1561,    109,     12,  14524,  15426,     26,\n",
              "             10,     91,      3,    188,   1632,   6668,   1263,      4,  10695,\n",
              "           2215,     12,    316,     58,    118,    124,     14,     30,     15,\n",
              "              5,     18,   1942,     11,    188,     12,     69,     22,   3162,\n",
              "           2487,   1475,    426,    752,    720,    111,      4,      6,     12,\n",
              "          10973,    284,     10,     66,     39,      1,    224,    264,     62,\n",
              "          27452,     12,      6,  10915,     31,     64,   2887,   1104,      3,\n",
              "            904,   2072,  24490,     10,   1286,    969,   5764,     12,    118,\n",
              "            124,     14,     30,     15,      5,     18,    357,   5797,  11909,\n",
              "             10,     66,     12,     39,    349,   1731,      6,    148,     64,\n",
              "            390,   1427,      8,   1807,   3448,     12,   1156,   4331,     10,\n",
              "              1,    393,     22,   1707,      9,     23,   2744,      4,   1344,\n",
              "             12,    635,    566,      4,   1033,      1,    750,   4057,      3,\n",
              "          54764,     34,   1792,  55127,    800,    191,   1530,    191,    135,\n",
              "            858,      4,    219,    448,   7781,   4486,     19,     44,   8249,\n",
              "              2,    369,    250,     40,   7448,     79,   1361,      1,    770,\n",
              "           1559,     51,    794,      3]),\n",
              " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
              " tensor([  0,  31,  73, 113, 153, 198, 244, 288, 333, 415, 450, 498, 557, 597,\n",
              "         648, 702]))"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(ds['train'],\n",
        "                          batch_size=16,\n",
        "                          shuffle=False,\n",
        "                          collate_fn = collate)\n",
        "\n",
        "next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2EyRgkIBZmM"
      },
      "source": [
        "Define the model\n",
        "----------------\n",
        "\n",
        "The model is composed of the [nn.EmbeddingBag](<https://pytorch.org/docs/stable/nn.html?highlight=embeddingbag#torch.nn.EmbeddingBag>) layer plus a linear layer for the classification purpose. ``nn.EmbeddingBag`` with the default mode of \"mean\" computes the mean value of a “bag” of embeddings. Although the text entries here have different lengths, nn.EmbeddingBag module requires no padding here since the text lengths are saved in offsets.\n",
        "\n",
        "Additionally, since ``nn.EmbeddingBag`` accumulates the average across\n",
        "the embeddings on the fly, ``nn.EmbeddingBag`` can enhance the\n",
        "performance and memory efficiency to process a sequence of tensors.\n",
        "\n",
        "![](https://pytorch.org/tutorials/_images/text_sentiment_ngrams_model.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6AcGnNiI5za"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim) #, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offset):\n",
        "        embedded = self.embedding(text, offset)\n",
        "        return self.fc(embedded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niRUlCBpEEsy"
      },
      "source": [
        "We will first initialize hyperparameters of our model, such as the vocabulary size and embedding dimension. With these, we can then initialize the model. This will also call the `init_weights` method automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZTehhb8I9JY"
      },
      "outputs": [],
      "source": [
        "num_class = len(set([x['label'] for x in ds['train']]))\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nI2EDR0ET1J"
      },
      "source": [
        "We can use predefined functions to train and evaluate the model at each epoch. Please note that each batch is sent to cuda separately. If this assignment is done elsewhere, it can cause you to run out of VRAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysWVwyjdJzlZ"
      },
      "outputs": [],
      "source": [
        "def accuracy(preds, y):\n",
        "    \"\"\" Return accuracy per batch. \"\"\"\n",
        "    preds = torch.argmax(preds, dim=-1)\n",
        "    correct = (preds == y).float()\n",
        "    return correct.sum() / len(correct)\n",
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    '''Train the model with specified data, optimizer, and loss function. '''\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for text, label, offset in iterator:\n",
        "        text, label, offset = text.to(device), label.to(device), offset.to(device)\n",
        "\n",
        "        predictions = model(text, offset)\n",
        "        loss = criterion(predictions, label)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        acc = accuracy(predictions, label)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    '''Evaluate model performance. '''\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # Turm off dropout while evaluating\n",
        "    model.eval()\n",
        "\n",
        "    # No need to backprop in eval\n",
        "    with torch.no_grad():\n",
        "        for text, label, offset in iterator:\n",
        "            text, label, offset = text.to(device), label.to(device), offset.to(device)\n",
        "\n",
        "            predictions = model(text, offset)\n",
        "            loss = criterion(predictions, label)\n",
        "            acc = accuracy(predictions, label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ofgBZD4D3xH"
      },
      "source": [
        "Initiating DataLoaders and Training Utilities\n",
        "-----------------------------------\n",
        "\n",
        "Since the original ``AG_NEWS`` has no validation split, we can separate the training\n",
        "set into train/valid sets with a split ratio of 0.95 (train) and\n",
        "0.05 (valid). Here we use\n",
        "[torch.utils.data.dataset.random_split](<https://pytorch.org/docs/stable/data.html?highlight=random_split#torch.utils.data.random_split>)\n",
        "function in PyTorch core library.\n",
        "\n",
        "\n",
        "[CrossEntropyLoss](<https://pytorch.org/docs/stable/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss>)\n",
        "criterion combines ``nn.LogSoftmax()`` and ``nn.NLLLoss()`` in a single class.\n",
        "It is useful when training a classification problem with C classes.\n",
        "[SGD](<https://pytorch.org/docs/stable/_modules/torch/optim/sgd.html>)\n",
        "implements stochastic gradient descent method as the optimizer. The initial\n",
        "learning rate is set to 5.0.\n",
        "[StepLR](<https://pytorch.org/docs/master/_modules/torch/optim/lr_scheduler.html#StepLR>)\n",
        "is used here to adjust the learning rate through epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6jU_hFvKyxB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "n_epochs = 10\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "\n",
        "train_split, val_split = random_split(ds['train'], [0.95, 0.05])\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_split,\n",
        "                          batch_size=16,\n",
        "                          shuffle=False,\n",
        "                          collate_fn = collate)\n",
        "\n",
        "val_loader = DataLoader(val_split,\n",
        "                        batch_size=16,\n",
        "                        shuffle=False,\n",
        "                        collate_fn = collate)\n",
        "\n",
        "test_loader = DataLoader(ds['test'],\n",
        "                        batch_size=16,\n",
        "                        shuffle=False,\n",
        "                        collate_fn = collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebomiV2gWCZO",
        "outputId": "1182f9c2-e191-4fc6-a479-83ef626f66e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TextClassificationModel(\n",
              "  (embedding): EmbeddingBag(110933, 64, mode='mean')\n",
              "  (fc): Linear(in_features=64, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR9ejVILE_mP"
      },
      "source": [
        "To take a quick look at what the model does let's give an example pair of \"sentences\". Here the tokens [1,2] would correspond to the first sentence, and the next one begins at index 2 and follows until the end.\n",
        "\n",
        "We get 4 logits representing the activation of each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RsR8vGUX30P",
        "outputId": "868eab36-1df5-4953-fc4f-edb2572fb22f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.1112, -0.6370,  0.0693,  0.4791],\n",
              "        [-0.2011, -0.5778,  0.2933, -0.1535]], device='cuda:0',\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.tensor([1,2,3,4,5,1]).to(device)\n",
        "c = torch.tensor([0,2]).to(device)\n",
        "\n",
        "model(a,c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quzWIKf7uX6B"
      },
      "source": [
        "## Training the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5vBFaWdKJzW",
        "outputId": "4d67cba0-4de3-4b40-e490-02e5729701ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  1 ended.\n",
            "\tTrain Loss: 0.405 | Train Acc: 85.68%\n",
            "\t Val. Loss: 0.311 |  Val. Acc: 89.88%\n",
            "Epoch  2 ended.\n",
            "\tTrain Loss: 0.251 | Train Acc: 91.55%\n",
            "\t Val. Loss: 0.295 |  Val. Acc: 90.43%\n",
            "Epoch  3 ended.\n",
            "\tTrain Loss: 0.206 | Train Acc: 93.19%\n",
            "\t Val. Loss: 0.308 |  Val. Acc: 90.40%\n",
            "Epoch  4 ended.\n",
            "\tTrain Loss: 0.141 | Train Acc: 95.37%\n",
            "\t Val. Loss: 0.287 |  Val. Acc: 90.87%\n",
            "Epoch  5 ended.\n",
            "\tTrain Loss: 0.129 | Train Acc: 95.82%\n",
            "\t Val. Loss: 0.290 |  Val. Acc: 90.90%\n",
            "Epoch  6 ended.\n",
            "\tTrain Loss: 0.122 | Train Acc: 96.03%\n",
            "\t Val. Loss: 0.294 |  Val. Acc: 90.92%\n",
            "Epoch  7 ended.\n",
            "\tTrain Loss: 0.117 | Train Acc: 96.25%\n",
            "\t Val. Loss: 0.298 |  Val. Acc: 90.87%\n",
            "Epoch  8 ended.\n",
            "\tTrain Loss: 0.109 | Train Acc: 96.48%\n",
            "\t Val. Loss: 0.292 |  Val. Acc: 91.12%\n",
            "Epoch  9 ended.\n",
            "\tTrain Loss: 0.108 | Train Acc: 96.52%\n",
            "\t Val. Loss: 0.292 |  Val. Acc: 91.10%\n",
            "Epoch 10 ended.\n",
            "\tTrain Loss: 0.107 | Train Acc: 96.56%\n",
            "\t Val. Loss: 0.291 |  Val. Acc: 91.18%\n"
          ]
        }
      ],
      "source": [
        "total_acc = None\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    # Get epoch losses and accuracies\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, val_loader, criterion)\n",
        "\n",
        "    if total_acc is not None and total_acc > valid_acc:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_acc = valid_acc\n",
        "\n",
        "    print(f'Epoch {epoch+1:2} ended.')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35ynujwKFkJW"
      },
      "source": [
        "Let's now evaluate the model performance on unseen examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh8Wl_8XOefD",
        "outputId": "dd835571-5926-4600-ecab-98f0679f5185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of our model on the test set is: 91.29%\n"
          ]
        }
      ],
      "source": [
        "_, test_acc = evaluate(model, test_loader, criterion)\n",
        "print(f'Accuracy of our model on the test set is: {test_acc:.2%}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mILzQS3OlDV",
        "outputId": "81ca046b-b056-4750-e276-d6a0a9531a8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a Sci/Tec article according to our model. (Confidence: 51.65%)\n"
          ]
        }
      ],
      "source": [
        "ag_news_label = {1: \"World\",\n",
        "                 2: \"Sports\",\n",
        "                 3: \"Business\",\n",
        "                 4: \"Sci/Tec\"}\n",
        "\n",
        "\n",
        "def predict(text, text_transform):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_transform(text)).to(device)\n",
        "        output = model(text, torch.tensor([0]).to(device))\n",
        "        pred = output.argmax(1).item()\n",
        "\n",
        "        soft = torch.nn.Softmax(dim=-1)\n",
        "        probs = soft(output).squeeze()\n",
        "        return pred+1, probs[pred].item()\n",
        "    model.train()\n",
        "\n",
        "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
        "    enduring the season’s worst weather conditions on Sunday at The \\\n",
        "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
        "    considering the wind and the rain was a respectable showing. \\\n",
        "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
        "    was another story. With temperatures in the mid-80s and hardly any \\\n",
        "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
        "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
        "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
        "    was even more impressive considering he’d never played the \\\n",
        "    front nine at TPC Southwind.\"\n",
        "\n",
        "_pred, _prob = predict(ex_text_str, text_transform)\n",
        "\n",
        "print(f'This is a {ag_news_label[_pred]} article according to our model. (Confidence: {_prob:.2%})')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp4vu1hPbCIN",
        "outputId": "065f1367-5334-4ded-a9da-ea41748c0a14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a Sci/Tec article according to our model. (Confidence: 58.92%)\n"
          ]
        }
      ],
      "source": [
        "other_ex = \"Hurricane Otis ripped across Mexico’s southern Pacific coast as a powerful Category 5 \\\n",
        "storm early Wednesday, tearing through buildings in the resort city of Acapulco, sending \\\n",
        "sheets of earth down steep mountainsides and leaving large swaths of the southwestern \\\n",
        "state of Guerrero without power or cellphone service. While little is known about \\\n",
        "possible deaths or the full extent of the damage — the main highway into Acapulco \\\n",
        "was impassable — experts are calling Otis the strongest storm in history to make \\\n",
        "landfall along the Eastern Pacific Coast.\"\n",
        "\n",
        "_pred, _prob = predict(other_ex, text_transform)\n",
        "\n",
        "print(f'This is a {ag_news_label[_pred]} article according to our model. (Confidence: {_prob:.2%})')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upTgruIZFtnc"
      },
      "source": [
        "Although results aren't bad, the model struggles somewhat in classifying the first paragraph, which turns out to be about golfing."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
